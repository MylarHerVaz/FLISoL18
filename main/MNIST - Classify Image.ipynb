{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make a simple yet useful processing...\n",
    "\n",
    "First of all, let's create some utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# model_utils.py\n",
    "\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load a trained model.\"\"\"\n",
    "\n",
    "    # Open model from JSON:\n",
    "    json_file = open('model.json', 'r')\n",
    "    model_json = json_file.read()\n",
    "    json_file.close()\n",
    "\n",
    "    # Load model:\n",
    "    model = model_from_json(model_json)\n",
    "\n",
    "    # Load weights into model:\n",
    "    model.load_weights(\"model.h5\")\n",
    "    print(\"Loaded model from disk.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def process_img(input_img):\n",
    "    \"\"\"A simple yet useful image processing.\"\"\"\n",
    "\n",
    "    # Read the input image\n",
    "    im = cv2.imread(input_img)\n",
    "\n",
    "    # Resize image if necessary:\n",
    "    if im.shape[1] > 3000 or im.shape[0] > 3000:\n",
    "        im = cv2.resize(im, (im.shape[1]//8, im.shape[0]//8))\n",
    "    elif im.shape[1] > 2000 or im.shape[0] > 2000:\n",
    "            im = cv2.resize(im, (im.shape[1]//4, im.shape[0]//4))\n",
    "    elif im.shape[1] > 1000 or im.shape[0] > 1000:\n",
    "        im = cv2.resize(im, (im.shape[1]//2, im.shape[0]//2))\n",
    "\n",
    "    # Convert to grayscale and apply Gaussian filtering:\n",
    "    im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    im_gray = cv2.GaussianBlur(im_gray, (5, 5), 0)\n",
    "\n",
    "    # Threshold the image:\n",
    "    ret, im_th = cv2.threshold(im_gray, 90, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find contours in the image:\n",
    "    im2, ctrs, hier = cv2.findContours(im_th.copy(),\n",
    "                                       cv2.RETR_EXTERNAL,\n",
    "                                       cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Get rectangles contains each contour:\n",
    "    rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "\n",
    "    return im, im_th, rects\n",
    "\n",
    "\n",
    "def predict(model, im, im_th, rects, output_img):\n",
    "    \"\"\"Predicting function.\"\"\"\n",
    "\n",
    "    # Results:\n",
    "    res = []\n",
    "\n",
    "    # For each rectangular region, predict the digit using CNN model:\n",
    "    for rect in sorted(rects):\n",
    "        # Draw the rectangles:\n",
    "        cv2.rectangle(im, (rect[0], rect[1]),\n",
    "                      (rect[0] + rect[2], rect[1] + rect[3]),\n",
    "                      (10, 255, 180), 3)\n",
    "\n",
    "        # Make the rectangular region around the digit:\n",
    "        leng = int(rect[3] * 1.2)\n",
    "        pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "        pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "        roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "\n",
    "        # Resize the image:\n",
    "        roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "        roi = cv2.dilate(roi, (3, 3))\n",
    "\n",
    "        # Reshape to be [samples][pixels][width][height]:\n",
    "        X = roi.reshape(1, 1, 28, 28).astype('float32')\n",
    "        X /= 255\n",
    "\n",
    "        # Predict digit:\n",
    "        nbr = np.argmax(model.predict(X))\n",
    "        res.append(nbr)\n",
    "        cv2.putText(im, str(nbr), (rect[0], rect[1]),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 2, (50, 190, 255), 3)\n",
    "\n",
    "    # Save results:\n",
    "    plt.imsave(output_img, im)\n",
    "    return ''.join(map(str, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do the magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk.\n"
     ]
    }
   ],
   "source": [
    "# We load a  trained model:\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's checkout our input image:\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"test.jpg\" width=\"50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 168\n"
     ]
    }
   ],
   "source": [
    "# We preproces the input image:\n",
    "img, img_th, rects = process_img(\"test.jpg\")\n",
    "\n",
    "#Let's make a prediction:\n",
    "out = predict(model, img, img_th, rects, \"output.jpg\")\n",
    "print(\"Prediction: {}\".format(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center>\n",
    "    <img src=\"output.jpg\" width=\"50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
